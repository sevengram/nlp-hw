__author__ = 'Jianxiang Fan'__email__ = 'jianxiang.fan@colorado.edu'import collectionsimport randomimport numpytest_rate = 0.0tag_map = {    '<S>': 0,    'O': 1,    'B': 2,    'I': 3,    '<E>': 4}tag_list = ['<S>', 'O', 'B', 'I', '<E>']def load_data(path, lower=True, test=False):    with open(path) as f:        sentence = []        for line in f:            if not line.strip():                yield sentence                sentence = []            else:                p = line.split('\t')                origin_token = p[0].strip()                sentence.append((origin_token,                                 tag_map[p[1].strip()] if not test else '',                                 origin_token.lower() if lower else origin_token))        if sentence:            yield sentencedef compute_transition_matrix(transition_counts):    return transition_counts / numpy.sum(transition_counts, axis=1)[:, numpy.newaxis]def compute_observation_matrix(token_counts, tag_counts, smoothing=False):    vocab_size = len(token_counts)    result = []    token_indices = {}    unk_count = numpy.zeros(len(tag_map) - 1)    alpha = 1 if smoothing else 0    for t, c in token_counts.iteritems():        if c[0] == 1:            unk_count += c        token_indices[t] = len(result)        result.append(            [(float(n + 1 * alpha) / (tag_counts[i] + vocab_size * alpha)) if i != 0 else 0 for i, n in enumerate(c)])    token_indices['UNK'] = len(result)    result.append([(float(n + 1 * alpha) / (tag_counts[i] + vocab_size * alpha)) if i != 0 else 0 for i, n in                   enumerate(unk_count)])    return numpy.array(result), token_indicesdef viterbi(trans_prob, obser_likeli, seq):    l, n = len(seq), len(trans_prob)    v = numpy.zeros((l, n))    back = numpy.zeros((l, n), dtype='int32')    for j in range(1, n):        v[0][j] = trans_prob[0][j] * obser_likeli[seq[0]][j]    for t in range(1, l):        for j in range(1, n):            pr = [v[t - 1][i] * trans_prob[i][j] * obser_likeli[seq[t]][j] for i in range(1, n)]            k = numpy.argmax(pr)            v[t][j] = pr[k]            back[t][j] = k + 1    result = [numpy.argmax([v[l - 1][i] * trans_prob[i][n] for i in range(1, n)]) + 1]    for j in range(l - 1, 0, -1):        result.append(back[j][result[-1]])    result.reverse()    return resultdef tokens_to_indices(seq, token_indices):    result = []    for t in seq:        if t not in token_indices:            t = 'UNK'        result.append(token_indices[t])    return resultdef output(fd, pair):    for p in pair:        fd.write('%s\t%s\n' % (p[0], tag_list[p[1]]))    fd.write('\n')if __name__ == '__main__':    n = len(tag_map)    transition_count = numpy.zeros((n - 1, n))    token_counts = collections.defaultdict(lambda: numpy.zeros(n - 1))    tag_count = numpy.zeros(n - 1)    test_set = []    for p in load_data('./data/gene.train.txt'):        if random.random() > test_rate:            last_tag = tag_map['<S>']            for origin_token, tag, token in p:                transition_count[last_tag][tag] += 1                last_tag = tag                tag_count[tag] += 1                token_counts[token][0] += 1                token_counts[token][tag] += 1            transition_count[last_tag][tag_map['<E>']] += 1        else:            test_set.append(p)    a = compute_transition_matrix(transition_count)    b, token_indices = compute_observation_matrix(token_counts, tag_count)    f2 = open('output/ans.txt', 'w')    if test_rate > 0.0:        f1 = open('output/refer.txt', 'w')        for seq in test_set:            output(f1, seq)            tags = viterbi(a, b, tokens_to_indices([t[2] for t in seq], token_indices))            output(f2, zip([t[0] for t in seq], tags))        f1.close()    else:        for seq in load_data('data/HW4-test.txt', test=True):            tags = viterbi(a, b, tokens_to_indices([t[2] for t in seq], token_indices))            ans = zip([t[0] for t in seq], tags)            output(f2, ans)    f2.close()